{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "872981be",
   "metadata": {},
   "source": [
    "# CAMEL Cookbook - Using MCP Tools in CAMEL (along with ACI.DEV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b34e9ad",
   "metadata": {},
   "source": [
    "**Description:** Learn how to build an object detection agent using CAMEL AI and ACI.dev's MCP protocol for seamless ML tasks. \n",
    "\n",
    "‚≠ê Star us on [GitHub](https://github.com/camel-ai/camel), join our [Discord](https://discord.gg/EXAMPLE), or follow us on [X](https://x.com/camelaiorg)\n",
    "\n",
    "This cookbook shows how to build a powerful object detection agent using CAMEL AI connected to ACI.dev's MCP tools. We'll create an agent that analyzes images, detects objects like cars or trees, and explains results in natural language‚Äîall without writing complex ML code.\n",
    "\n",
    "**Key Learnings:**\n",
    "- History about function calling for LLMs.\n",
    "- What is Model Context Protocols (MCP)?\n",
    "- How MCP enables dynamic, aware tool usage for tasks like object detection.\n",
    "- Setting up CAMEL with ACI.dev for real-time image analysis.\n",
    "- Building and running your own object detection agent.\n",
    "- Handling outputs with summaries, tables, and visualized results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225d789a",
   "metadata": {},
   "source": [
    "### Introduction to Model Context Protocols (MCP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb8eb19",
   "metadata": {},
   "source": [
    "#### A Brief History of function calling and MCP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d7e36a",
   "metadata": {},
   "source": [
    "- **Pre-2023 - When LLMs Lacked Environmental Awareness**:\n",
    "  - Tool usage implemented via prompt engineering \n",
    "  - Support provided at framework level (e.g., LangChain, CAMEL agents)\n",
    "  - No native capabilities; relied on parsing unstructured model outputs\n",
    "- **June 2023 ‚Äì OpenAI Launches Native Function Calling Ability**:\n",
    "  - Introduced in GPT-4 and GPT-3.5-turbo\n",
    "  - Utilized structured JSON outputs to call tools and pass arguments\n",
    "  - Enabled significantly more reliable and scalable tool integration\n",
    "- **Nov 2024 ‚Äì Anthropic Proposes MCP (Model Context Protocol)**:\n",
    "  - Formalizes tool interaction using JSON-RPC 2.0 standard\n",
    "  - Standardizes communication between AI systems and external tools/resources\n",
    "- **2025 ‚Äì Industry-Wide Adoption**:\n",
    "  - OpenAI, DeepMind, and other major players adopt MCP\n",
    "  - Function calling becomes a core capability for advanced agentic AI systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c98d9",
   "metadata": {},
   "source": [
    "#### Why MCP? \n",
    "\n",
    "The power of standardization:\n",
    "  \n",
    "![](figs/MCP.png){fig-align=\"center\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a5ff5",
   "metadata": {},
   "source": [
    "#### MCP Ecosystem\n",
    "\n",
    "MCP Clients:\n",
    "- Claude desktop\n",
    "- Coding Tools: Cursor/Windsurf, Claude Code, Cline.\n",
    "- Frameworks like CAMEL, LangChain.\n",
    "\n",
    "MCP is gradually becoming a standard. Here are some useful MCP repositories:\n",
    "\n",
    "- <a href=\"https://www.aci.dev\" target=\"_blank\">ACI.dev</a>\n",
    "- <a href=\"https://smithery.ai\" target=\"_blank\">Smithery</a>\n",
    "- <a href=\"https://composio.dev/\" target=\"_blank\">Composio</a>\n",
    "- <a href=\"https://mcp.run/\" target=\"_blank\">mcp.run</a>\n",
    "- <a href=\"https://www.modelscope.cn/mcp\" target=\"_blank\">ModelScope</a>\n",
    "- <a href=\"https://github.com/punkpeye/awesome-mcp-servers\" target=\"_blank\">Awesome MCP Servers</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4030d2b7",
   "metadata": {},
   "source": [
    "#### CAMEL's Integration with MCP\n",
    "\n",
    "In this section, we'll explore how CAMEL is integrating with the Model Context Protocol to create a more powerful and flexible agent framework. Here's what we'll cover:\n",
    "\n",
    "1. Agent using MCP tools\n",
    "2. Export CAMEL existing tools as MCP servers\n",
    "3. MCP search toolkits/ MCP search agents\n",
    "4. Export CAMEL agents as MCP servers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ad4834",
   "metadata": {},
   "source": [
    "### üì¶ Installation and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4c4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install camel-ai aci-mcp aci-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523e21e0",
   "metadata": {},
   "source": [
    "Set up keys (ACI_API_KEY, LINKED_ACCOUNT_OWNER_ID, GOOGLE_API_KEY, REPLICATE_API_TOKEN) in `.env` file. Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e484b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "from camel.agents import ChatAgent\n",
    "from camel.messages import BaseMessage\n",
    "from camel.models import ModelFactory\n",
    "from camel.types import ModelPlatformType, ModelType\n",
    "from camel.toolkits import MCPToolkit, PulseMCPSearchToolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf512d1",
   "metadata": {},
   "source": [
    "### Hands on MCP servers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c7694b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have real-time capabilities to provide the current time. You might want to check a clock, smartphone, or a computer that has internet access to find the current time in Riyadh. Riyadh operates on Arabia Standard Time (AST), which is UTC+3.\n"
     ]
    }
   ],
   "source": [
    "agent = ChatAgent(model=\"gpt-4o\")\n",
    "response = agent.step(\"Hi GPT, what is the current time? I am Riyadh.\")\n",
    "print(response.msg.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3faeddc0",
   "metadata": {},
   "source": [
    "So, the agent know nothing about the time! Let's find some MCP server and equip agent this ability!\n",
    "For example: https://github.com/modelcontextprotocol/servers/tree/main/src/time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ef59816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tools:\n",
      "['get_current_time', 'convert_time']\n",
      "2025-07-31 11:00:48,949 - camel.camel.agents.chat_agent - WARNING - Model type 'gpt-4o' provided without a platform. Using platform 'ModelPlatformType.DEFAULT'. Note: platform is not automatically inferred based on model type.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinx0a/micromamba/envs/camel-ai-env/lib/python3.12/site-packages/camel/memories/blocks/chat_history_block.py:73: UserWarning: The `ChatHistoryMemory` is empty.\n",
      "  warnings.warn(\"The `ChatHistoryMemory` is empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current time in Riyadh is 11:00 AM on July 31, 2025.\n"
     ]
    }
   ],
   "source": [
    "config_dict = {\n",
    "  \"mcpServers\": {\n",
    "    \"time\": {\n",
    "      \"command\": \"uvx\",\n",
    "      \"args\": [\"mcp-server-time\", \"--local-timezone=Asia/Riyadh\"]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "async with MCPToolkit(config_dict=config_dict) as toolkit:\n",
    "    print(\"Available tools:\")\n",
    "    print([tool.get_function_name() for tool in toolkit.get_tools()])\n",
    "\n",
    "    agent = ChatAgent(model=\"gpt-4o\", tools=toolkit.get_tools())\n",
    "    response = await agent.astep(\"What is the current time? I am in Riyadh.\")\n",
    "    print(response.msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f973269",
   "metadata": {},
   "source": [
    "Great! Now our agent are aware of the current time now! \n",
    "\n",
    "How about other tools? Where to find the interesting and useful tools? There are a lot of MCP registry platforms. \n",
    "Let's use <a href=\"https://www.aci.dev\" target=\"_blank\">ACI.dev</a> as an example!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b813db0e",
   "metadata": {},
   "source": [
    "### Example of using replicate on ACI.dev to do object detection!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eda6189",
   "metadata": {},
   "source": [
    "Let's say we want to do the object detection, as the Takhom company do.\n",
    "\n",
    "We can search the related MCP tools within CAMEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d66d8721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'servers': [{'name': 'ImageSorcery',\n",
       "   'url': 'https://www.pulsemcp.com/servers/sunriseapps-imagesorcery',\n",
       "   'external_url': None,\n",
       "   'short_description': 'Provides powerful image manipulation capabilities including resizing, cropping, object detection, OCR text extraction, and finding objects based on text descriptions using Python with OpenCV and Ultralytics',\n",
       "   'source_code_url': 'https://github.com/sunriseapps/imagesorcery-mcp',\n",
       "   'github_stars': 85,\n",
       "   'package_registry': 'pypi',\n",
       "   'package_name': 'imagesorcery-mcp',\n",
       "   'package_download_count': 7687,\n",
       "   'EXPERIMENTAL_ai_generated_description': 'ImageSorcery MCP provides AI assistants with powerful image manipulation capabilities through a standardized interface. Built with Python using OpenCV and Ultralytics, it offers tools for basic operations like resizing, cropping, and rotating images, as well as advanced features including object detection, OCR text extraction, and finding objects based on text descriptions. The server implements a modular architecture with comprehensive logging and error handling, supporting various pre-trained models that can be downloaded on demand. Particularly valuable for applications requiring image analysis, content moderation, and visual information extraction without requiring users to have specialized image processing knowledge.',\n",
       "   'remotes': []},\n",
       "  {'name': 'YOLO Computer Vision',\n",
       "   'url': 'https://www.pulsemcp.com/servers/gongrzhe-yolo-computer-vision',\n",
       "   'external_url': None,\n",
       "   'short_description': 'Enables computer vision capabilities using YOLO models for object detection, segmentation, classification, and pose estimation on images and camera feeds',\n",
       "   'source_code_url': 'https://github.com/gongrzhe/yolo-mcp-server',\n",
       "   'github_stars': 17,\n",
       "   'package_registry': None,\n",
       "   'package_name': None,\n",
       "   'package_download_count': None,\n",
       "   'EXPERIMENTAL_ai_generated_description': 'The YOLO MCP Server enables AI assistants to perform computer vision tasks using state-of-the-art YOLO (You Only Look Once) models. Built with Python using FastMCP and Ultralytics, it provides tools for object detection, segmentation, classification, and pose estimation on images, as well as real-time camera analysis. The implementation offers both direct model integration and CLI-based approaches, supports model training and validation, and includes comprehensive image analysis that combines multiple model results. This server bridges the gap between AI assistants and computer vision capabilities, making it valuable for applications requiring visual understanding of user-provided images or camera feeds.',\n",
       "   'remotes': []},\n",
       "  {'name': 'Moondream',\n",
       "   'url': 'https://www.pulsemcp.com/servers/nighttrek-moondream',\n",
       "   'external_url': None,\n",
       "   'short_description': 'Provide image analysis capabilities including captioning, object detection, and visual question answering for applications like content moderation and visual search.',\n",
       "   'source_code_url': 'https://github.com/nighttrek/moondream-mcp',\n",
       "   'github_stars': 16,\n",
       "   'package_registry': None,\n",
       "   'package_name': None,\n",
       "   'package_download_count': None,\n",
       "   'EXPERIMENTAL_ai_generated_description': 'This Moondream MCP server, developed by an unknown author, provides image analysis capabilities through the Model Context Protocol. Built with TypeScript and leveraging the Moondream Python package, it offers tools for image captioning, object detection, and visual question answering. The server manages its own Python environment and model setup, downloading a quantized model for efficient processing. By abstracting complex image analysis tasks into a standardized MCP interface, it enables AI systems to easily incorporate visual understanding into their workflows. This implementation is particularly useful for applications involving image content analysis, automated image captioning, and visual data extraction, facilitating use cases such as content moderation, accessibility improvements, and visual search functionalities.',\n",
       "   'remotes': []}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_toolkit = PulseMCPSearchToolkit()\n",
    "search_toolkit.search_mcp_servers(\n",
    "    query=\"Object detection\",\n",
    "    top_k=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4511afbe",
   "metadata": {},
   "source": [
    "For today's illustration, we will use Replicate API to do it.\n",
    "\n",
    "**Replicate** is a developer-friendly platform that hosts a wide collection of open-source AI models for tasks such as:\n",
    "\n",
    "‚Ä¢\tText-to-image generation (e.g., Stable Diffusion, DALL¬∑E)\n",
    "\n",
    "‚Ä¢\tAudio transcription (e.g., Whisper)\n",
    "\n",
    "‚Ä¢\tChat and language models (e.g., LLaMA, Mistral)\n",
    "\n",
    "‚Ä¢\tImage-to-image transformation (e.g., face restoration, background removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b399254",
   "metadata": {},
   "source": [
    "In ACI.dev, we can find the [Replicate MCP server](https://platform.aci.dev/apps/REPLICATE) with 2 tools:\n",
    "\n",
    "- REPLICATE__MODEL_GROUNDING_DINO: Detects any object in an image based on a descriptive text query. It can detect objects it wasn't explicitly trained on.\n",
    "\n",
    "- REPLICATE__MODEL_FLUX_1_1_PRO: Faster, better FLUX Pro. Text-to-image model with excellent image quality, prompt adherence, and output diversity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c518f614",
   "metadata": {},
   "source": [
    "Let's start our by agent by setting the prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df8125d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "agent_name = \"ObjectDetectionAgent\"\n",
    "system_prompt=\"\"\"\n",
    "You are a specialized Object Detection Agent. Your primary function is to use the `REPLICATE.run` tool for object detection and present the findings in a user-friendly format. \"\n",
    "\"The user will provide a text prompt containing an image URL and a query. You must extract the `image` URL and the `query` object(s). \"\n",
    "\"Immediately call the `REPLICATE.run` tool. The `input` must be a dictionary with two keys: `image` (the URL) and `query` (a string of the object(s)). \"\n",
    "\"Do not ask for clarification; make a reasonable inference if the query is ambiguous. \"\n",
    "\"After receiving the tool's output, format your response as follows: \"\n",
    "\"- **Natural Language Summary:** Start with a detailed friendly, insightful analysis of the detection results in plain English. \"\n",
    "\"- **Markdown Table:** Create a markdown table with columns: 'Object', 'Confidence Score', and 'Bounding Box Coordinates'. \"\n",
    "\"- **Result Image:** If the tool provides a URL for an image with bounding boxes, display it using markdown: `![Detected Objects](URL_HERE)`. \"\n",
    "\"Whenever I give you a link, trigger the tool call, extract its outputs and links, and present me in a proper markdown format with detailed analysis from the tool call in natural language.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de159dc",
   "metadata": {},
   "source": [
    "### MCP servers configuration using ACI.dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b360b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_config = {\n",
    "    \"mcpServers\": {\n",
    "        \"aci_apps\": {\n",
    "            \"command\": \"aci-mcp\",\n",
    "            \"args\": [\n",
    "                \"apps-server\",\n",
    "                \"--apps=REPLICATE\",\n",
    "                \"--linked-account-owner-id\",\n",
    "                \"tahakom\"\n",
    "            ],\n",
    "            \"env\": {\n",
    "                \"ACI_API_KEY\": os.getenv(\"ACI_API_KEY\")\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f65a18",
   "metadata": {},
   "source": [
    "Define the CAMEL agent with this configuration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "834b52ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_toolkit = MCPToolkit(config_dict=mcp_config)\n",
    "await mcp_toolkit.connect()\n",
    "tools = mcp_toolkit.get_tools()\n",
    "\n",
    "# Initialize Gemini model\n",
    "model = ModelFactory.create(\n",
    "    model_platform=ModelPlatformType.OPENAI,\n",
    "    model_type=ModelType.GPT_4_1,\n",
    ")\n",
    "\n",
    "# Create system message\n",
    "sys_msg = BaseMessage.make_assistant_message(\n",
    "    role_name=agent_name,\n",
    "    content=system_prompt,\n",
    ")\n",
    "\n",
    "agent = ChatAgent(model=model, system_message=sys_msg, tools=tools, memory=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34c9a64",
   "metadata": {},
   "source": [
    "After create the agent, let's do some examples using Replicate to identify the following images:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4304b8ff",
   "metadata": {},
   "source": [
    "Now you can start the interactive chat loop to analyze any image URL you provide!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51551c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Object Detection Chat! Enter 'quit' to exit.\n",
      "Please provide an image URL and what objects you'd like to detect.\n",
      "Example format: Analyze this image for cars and people: [IMAGE_URL]\n",
      "\n",
      "Analysis Results:\n",
      "- **Natural Language Summary:**\n",
      "  Upon analyzing the vegetable stall in the provided image, several types of produce were successfully detected. Tomatoes and onions are well represented in various locations across the stall, with multiple bounding boxes showing their presence. Notably, carrots and cabbages are also detected, positioned in distinct sections. Zucchini and cucumber are each identified, demonstrating a diverse offering of fresh vegetables. There is also a detection for beet, though with somewhat lower confidence. Overall, the stall features an abundant and well-organized display of fresh vegetables, and all queried items have been identified with moderate confidence.\n",
      "\n",
      "- **Markdown Table:**\n",
      "\n",
      "| Object    | Confidence Score | Bounding Box Coordinates      |\n",
      "|-----------|------------------|------------------------------|\n",
      "| carrot    | 0.47             | [294, 916, 1001, 1438]       |\n",
      "| cabbage   | 0.50             | [110, 1982, 1436, 3150]      |\n",
      "| onion     | 0.41             | [742, 3535, 1378, 4186]      |\n",
      "| onion     | 0.42             | [778, 4032, 1507, 4837]      |\n",
      "| onion     | 0.37             | [10, 3733, 785, 4501]        |\n",
      "| cabbage   | 0.33             | [6, 3088, 1022, 3850]        |\n",
      "| tomato    | 0.41             | [1214, 2242, 3445, 3768]     |\n",
      "| tomato    | 0.33             | [1913, 2846, 2537, 3407]     |\n",
      "| onion     | 0.32             | [4, 4434, 568, 5173]         |\n",
      "| tomato    | 0.29             | [1782, 4008, 2517, 4669]     |\n",
      "| tomato    | 0.25             | [1503, 4515, 2212, 5172]     |\n",
      "| zucchini  | 0.44             | [727, 1767, 1538, 2331]      |\n",
      "| beet      | 0.26             | [1039, 433, 1360, 687]       |\n",
      "| tomato    | 0.29             | [1662, 2397, 2211, 2920]     |\n",
      "| tomato    | 0.33             | [1501, 3778, 3446, 5172]     |\n",
      "| onion     | 0.26             | [725, 4798, 1447, 5176]      |\n",
      "| cucumber  | 0.31             | [213, 1482, 1066, 1785]      |\n",
      "| carrot    | 0.31             | [296, 1079, 951, 1422]       |\n",
      "| onion     | 0.26             | [9, 3543, 1500, 5171]        |\n",
      "\n",
      "- **Result Image:**\n",
      "![Detected Objects](https://replicate.delivery/xezq/I7wet7IqQ4zNTaz1RcLy0b6CGeAj5g4fkC8J7laivxkkoaMqA/result.png)\n",
      "Thank you for using the Object Detection Chat!\n"
     ]
    }
   ],
   "source": [
    "# Sample prompts for reference:\n",
    "# 1. \"Analyze the vegetable stall and identify all produce, including tomato, onion, cabbage, cucumber, zucchini, carrot, and beet, in this image: https://images.pexels.com/photos/2255935/pexels-photo-2255935.jpeg\"\n",
    "# 2. \"Analyze the busy street scene and identify all vehicles, such as car, bus, and truck, as well as people, in this image: https://www.livemint.com/rf/Image-621x414/LiveMint/Period1/2012/10/01/Photos/Road621.jpg\"\n",
    "# 3. \"Analyze the warehouse scene and identify persons, cardboard boxes, and conveyor belts in this image: https://media.business-humanrights.org/media/images/16278498935_dac4d8f223_o.2e16d0ba.fill-1000x1000-c50.jpg\"\n",
    "\n",
    "print(\"Welcome to the Object Detection Chat! Enter 'quit' to exit.\")\n",
    "print(\"Please provide an image URL and what objects you'd like to detect.\")\n",
    "print(\"Example format: Analyze this image for cars and people: [IMAGE_URL]\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"\\nEnter your prompt: \").strip()\n",
    "        \n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"Thank you for using the Object Detection Chat!\")\n",
    "            break\n",
    "            \n",
    "        if not user_input:\n",
    "            print(\"Please enter a valid prompt with an image URL.\")\n",
    "            continue\n",
    "            \n",
    "        response = await agent.astep(user_input)\n",
    "        print(\"\\nAnalysis Results:\")\n",
    "        print(response.msg.content)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        print(\"Please try again with a different image URL or prompt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e942e",
   "metadata": {},
   "source": [
    "Besides using CAMEL agent to connect to the MCP servers, we can export CAMEL agent as MCP servers in one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb101f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp = agent.to_mcp(name=\"ObjectDetectionAgent\")\n",
    "# mcp.run(transport=\"streamable-http\") # run this in script, not notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a41f02d",
   "metadata": {},
   "source": [
    "After that, we can call it using other MCP clients such as Claude desktop, Cursor, etc.\n",
    "\n",
    "Finally, we disconnect the MCP toolkit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ddd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "await mcp_toolkit.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc243759",
   "metadata": {},
   "source": [
    "### Other usecases\n",
    "\n",
    "Other resources from CAMEL-AI:\n",
    "\n",
    "- SQL MCP Server: https://docs.camel-ai.org/cookbooks/mcp/agents_with_sql_mcp\n",
    "\n",
    "- Pairing AI Agents with 600+ MCP Tools via ACI.dev: https://docs.camel-ai.org/cookbooks/mcp/camel_aci_mcp_cookbook\n",
    "\n",
    "- CAMEL MCP Hub: https://mcp.camel-ai.org"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
